{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Models Used\nI have implemented three models for denoising the Cifar-10 dataset. These are: \n1. Convolutional Auto-encoders with Symmetric Skip Connections [[link]](https://arxiv.org/pdf/1606.08921.pdf)\n2. WIN5, WIN5-R and WIN5-RB based on Wide inference Networks [[link]](https://arxiv.org/pdf/1707.05414.pdf)\n3. RIDNet [[link](https://arxiv.org/pdf/1904.07396v2.pdf)]\n\n### Noise Types\nI have tested the model on 2 types of noises. These are: \n1. Gaussian Noise (mean=0, [var=0.01 and var=0.05])\n2. Salt and Pepper Noise (s&p)\n\n<b>Note: Please refer to the results document sent on sabyasachis@iisc.ac.in for the model results.** <br /> <br />\nNote: All the models were trained using a scheduler. Running the model as per the hypermeters in the notebook may not give the same results as in the results** document sent on sabyasachis@iisc.ac.in. Please mail at abhinavnagpal12@gmail.com for the scheduler details.</b>\n"},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\nimport os\nimport skimage\nimport cv2\nfrom skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.utils import plot_model\nfrom keras.layers import * #Conv2D, Input, Concatenate, Dense,Dropout, AveragePooling2D, GlobalAveragePooling3D, GlobalAveragePooling2D, GlobalAveragePooling1D, ReLU, MaxPool2D, UpSampling2D, Conv2DTranspose, BatchNormalization,add, Add, LeakyReLU\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Noise Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_noise(data, mean, var, noise):\n    sigma = var**0.5\n    num,row,col,ch = data.shape\n\n    if noise == \"gaussian\":\n        normal = np.random.normal(mean,sigma,(num,row,col,ch))\n        normal = normal.reshape(num,row,col,ch)\n        noisy = data + normal\n    elif noise == \"s&p\": \n        noisy = skimage.util.random_noise(data, mode=noise)\n        \n#     elif noise == \"rand_black\":\n#         print(2)\n\n#     elif noise == \"rand_color\":\n#         print(3)\n    \n\n#     elif noise == \"poisson\":\n#         mask = numpy.random.poisson(data)\n#         noisy = data + mask\n    \n#     elif noise == \"speckle\":\n#         normal = np.random.normal(mean,sigma,(num,row,col,ch))\n#         normal = normal.reshape(num,row,col,ch)        \n#         noisy = data + data*normal\n    \n    return noisy","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display Noisy V/S Original"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(noisy, original, n):\n    plt.figure(figsize=(15,15))\n\n    ids = np.random.randint(low = len(noisy), size = n)\n\n    for i in range(len(ids)):\n        plt.subplot(n, 2, (2*(i+1))-1)\n        plt.imshow(noisy[ids[i]])\n        plt.title('Noisy')\n        plt.axis(\"off\")\n\n        plt.subplot(n, 2, 2*(i+1))\n        plt.imshow(original[ids[i]])\n        plt.title('Original')\n        plt.axis(\"off\")\n        \n    plt.show()","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot Loss Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_plot(history):\n    f = plt.figure(figsize=(7,5))\n    f.add_subplot()\n    plt.plot(history.epoch, history.history['loss'], label = \"loss\") # train loss\n    plt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\") # validation loss\n    plt.title(\"Loss Curves\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.grid(alpha=0.5)\n    plt.legend()\n    plt.show()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display Noisy v/s Denoised samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_denoised(x_test, y_test, model, num_images):\n    col = 6\n    row = int(num_images/col)\n    cell_size = 1.5\n    \n    ids = np.random.randint(x_test.shape[0], size = num_images) \n    \n    cifar_test = x_test[ids]\n    cifar_original = y_test[ids]\n    cifar_denoised = model.predict(cifar_test)\n    \n    f = plt.figure(figsize=(cell_size*col,cell_size*row*3))\n    \n    for i in range(row):\n        \n        for j in range(col): \n            f.add_subplot(row*3,col, (3*i*col)+(j+1)) \n            plt.imshow(cifar_original[i*col + j]) \n            plt.axis(\"off\")\n            plt.title('Original')\n        \n        for j in range(col): \n            f.add_subplot(row*3,col,((3*i+1)*col)+(j+1))\n            plt.imshow(cifar_test[i*col + j]) \n            plt.axis(\"off\")\n            plt.title('Noisy')\n\n        for j in range(col): \n            f.add_subplot(row*3,col,((3*i+2)*col)+(j+1))\n            plt.imshow(cifar_denoised[i*col + j]) \n            plt.axis(\"off\")\n            plt.title('De-noised')\n\n\n    f.suptitle(\"Results\",fontsize=20)\n    plt.show()","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get PSNR and SSIM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_metric(model, x_test, y_test):\n    results = model.predict(x_test) # predict\n    y_test = y_test.astype('float32')\n    s = 0\n    p = 0\n    for i in range(x_test.shape[0]):\n        p+=peak_signal_noise_ratio(y_test[i], results[i])\n        s+=structural_similarity(y_test[i], results[i],multichannel=True)\n    \n    return p/10000, s/10000","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 1: Convolutional Auto-encoders with Symmetric Skip Connections [[link]](https://arxiv.org/pdf/1606.08921.pdf)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(layers.Layer):        \n        \n    def __init__(self, name=\"encoder\", **kwargs):\n        super(Encoder, self).__init__(name=name, **kwargs)\n        self.conv_1 = Conv2D(32, 3, activation='relu', padding='same')\n        self.bn1 = BatchNormalization()\n        self.mp = MaxPool2D()\n        self.dropout = Dropout(0.5)\n        self.conv_2 = Conv2D(32, 3, padding='same')\n        self.bn2 = BatchNormalization()\n        self.lr = LeakyReLU()\n        self.conv_3 = Conv2D(64, 3, activation='relu', padding='same')\n        self.bn3 = BatchNormalization()\n        \n    def call(self, inputs):\n        x = self.conv_1(inputs)\n        x = self.bn1(x)\n        x = self.mp(x)\n        x = self.dropout(x)\n        skip = self.conv_2(x)\n        x = self.lr(skip)\n        x = self.bn2(x)\n        x = self.mp(x)\n        x = self.dropout(x)\n        x = self.conv_3(x)\n        x = self.bn3(x)\n        encoder_output = self.mp(x)\n        return encoder_output, skip\n\nclass Decoder(layers.Layer):\n\n    def __init__(self, name=\"decoder\", **kwargs):\n        super(Decoder, self).__init__(name=name, **kwargs)\n        \n        self.conv_t1 = Conv2DTranspose(64, 3,activation='relu',strides=(2,2), padding='same')\n        self.bn1 = BatchNormalization()\n        self.dropout = Dropout(0.5)\n        self.conv_t2 = Conv2DTranspose(32, 3, activation='relu',strides=(2,2), padding='same')\n        self.bn2 = BatchNormalization()\n        self.conv_t3 = Conv2DTranspose(32, 3, padding='same')\n        self.lr = LeakyReLU()\n        self.conv_t4 = Conv2DTranspose(3, 3, activation='sigmoid',strides=(2,2), padding='same')\n        self.bn3 = BatchNormalization()\n\n    def call(self, inputs, skip):\n        \n        x = self.conv_t1(inputs)\n        x = self.bn1(x)\n        x = self.dropout(x)\n        x = self.conv_t2(x)\n        x = self.bn2(x)\n        x = self.dropout(x)\n        x = self.conv_t3(x)\n        x = add([x,skip]) # adding skip connection\n        x = self.lr(x)\n        x = self.bn3(x)\n        decoder_output = self.conv_t4(x)\n        return decoder_output\n\n\nclass AutoEncoder(keras.Model):\n\n    def __init__(self,original_dim,name=\"autoencoder\",**kwargs):\n        super(AutoEncoder, self).__init__(name=name, **kwargs)\n        self.original_dim = original_dim\n        self.encoder = Encoder()\n        self.decoder = Decoder()\n\n    def call(self, inputs):\n        encoder_output, skip = self.encoder(inputs)\n        decoder_output = self.decoder(encoder_output, skip)\n        return decoder_output\n    \n    def model(self):\n        x = Input(shape=(32,32,3))\n        return Model(inputs=[x], outputs=self.call(x))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main(show_sample = True):\n    # Loading the dataset\n    (x_train, _), (x_test, _) = cifar10.load_data()\n\n    # Scale the images beteen 0 and 1\n    x_train = x_train/255.0\n    x_test = x_test/255.0\n\n    # Real images are labels\n    y_train = x_train\n    y_test = x_test\n\n    # Adding noise to the images\n    noise = \"gaussian\"\n    mean = 0\n    var = 0.01\n\n    x_train = add_noise(y_train, mean, var, noise)\n    x_test = add_noise(y_test, mean, var, noise)\n\n#   display noisy and original images\n    num_img=5\n    show_images(x_train, y_train, num_img)\n    \n    ae = AutoEncoder((32,32,3))\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n    ae.compile(optimizer=Adam(lr=0.00001), loss='mae')\n    return x_train, y_train, x_test, y_test, ae","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x_train, y_train, x_test, y_test, ae = main() \nepochs = 65\nbatch_size = 256\n        \nhistory = ae.fit(x_train, y_train, validation_data = (x_test, y_test), shuffle=True, epochs=epochs, batch_size=batch_size)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_plot(history)\ndisplay_denoised(x_test, y_test, ae, num_images=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"psnr, ssim = get_metric(ae, x_test, y_test)\nprint(psnr, ssim)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 2: Wide Inference Network for Image Denoising via Learning Pixel-distribution Prior [[link]](https://arxiv.org/pdf/1707.05414.pdf)"},{"metadata":{},"cell_type":"markdown","source":"### Type 1: WIN5"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, _), (x_test, _) = cifar10.load_data()\n\n# Scaling the images beteen 0 and 1\nx_train = x_train/255.0\nx_test = x_test/255.0\n\n# Real images are labels\ny_train = x_train\ny_test = x_test\n\n# Adding noise to the images\nnoise = \"gaussian\"\nmean = 0\nvar = 0.01\n\nx_train = add_noise(y_train, mean, var, noise)\nx_test = add_noise(y_test, mean, var, noise)\n\nX = Input((32,32,3))\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(X)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(3, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\n\nmodel = Model(inputs = X, outputs = x)\nmodel.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001), loss = 'mae')\n# model.summary()","execution_count":9,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 4s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nbatch_size = 64\nhistory = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"display_denoised(x_test, y_test, model, num_images=12)\ndraw_plot(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(get_metric(model, x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Type 2: WIN5-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, _), (x_test, _) = cifar10.load_data()\n\n# Scaling the images beteen 0 and 1\nx_train = x_train/255.0\nx_test = x_test/255.0\n\n# Real images are labels\ny_train = x_train\ny_test = x_test\n\n# Adding noise to the images\nnoise = \"gaussian\"\nmean = 0\nvar = 0.01\n\nx_train = add_noise(y_train, mean, var, noise)\nx_test = add_noise(y_test, mean, var, noise)\n\nX = Input((32,32,3))\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(X)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = ReLU()(x)\n\nx = Conv2D(3, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = Add()([X, x])\n\nmodel = Model(inputs = X, outputs = x)\nmodel.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001), loss = 'mae')\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 15\nbatch_size = 64\n# model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.05), loss = 'mse')\nhistory = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_denoised(x_test, y_test, model, num_images=12)\ndraw_plot(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(get_metric(model, x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Type 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, _), (x_test, _) = cifar10.load_data()\n\n# Scaling the images beteen 0 and 1\nx_train = x_train/255.0\nx_test = x_test/255.0\n\n# Real images are labels\ny_train = x_train\ny_test = x_test\n\n# Adding noise to the images\nnoise = \"gaussian\"\nmean = 0\nvar = 0.01\n\nx_train = add_noise(y_train, mean, var, noise)\nx_test = add_noise(y_test, mean, var, noise)\n\nX = Input((32,32,3))\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(X)\nx = BatchNormalization()(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = BatchNormalization()(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = BatchNormalization()(x)\nx = ReLU()(x)\n\nx = Conv2D(128, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = BatchNormalization()(x)\nx = ReLU()(x)\n\nx = Conv2D(3, 7, padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4))(x)\nx = BatchNormalization()(x)\nx = Add()([X, x])\n\nmodel = Model(inputs = X, outputs = x)\nmodel.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01), loss = 'mae')\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 15\nbatch_size = 64\n# model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001), loss = 'mae')\nhistory = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_denoised(x_test, y_test, model, num_images=12)\nprint(get_metric(model, x_test, y_test))\ndraw_plot(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 3: RIDNet [[link](https://arxiv.org/pdf/1904.07396v2.pdf)]\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def eam_block(x):\n    \n    # merge and run\n    x1 = Conv2D(64, 3, padding='same')(x)\n    x1 = ReLU()(x1)\n    x1 = Conv2D(64, 3, padding='same', dilation_rate = 2)(x1)\n    x1 = ReLU()(x1)\n\n    x2 = Conv2D(64, 3, padding='same', dilation_rate = 3)(x)\n    x2 = ReLU()(x2)\n    x2 = Conv2D(64, 3, padding='same', dilation_rate = 4)(x2)\n    x2 = ReLU()(x2)\n\n    merge1 = Concatenate()([x1,x2])\n    merge1 = Conv2D(64, 3, padding='same')(merge1)\n    merge1 = ReLU()(merge1)\n    merge1 = merge1+x\n\n    # residual block\n    r1  = Conv2D(64, 3, padding='same')(merge1)\n    r1 = ReLU()(r1)\n    r1 = Conv2D(64, 3, padding='same')(r1)\n    r1 = ReLU()(r1+merge1)\n\n    # e-residual block \n    er1  = Conv2D(64, 3, padding='same')(r1)\n    er1 = ReLU()(er1)\n    er1 = Conv2D(64, 3, padding='same')(er1)\n    er1 = ReLU()(er1)\n    er1  = Conv2D(64, 1, padding='valid')(er1)\n    er1 = ReLU()(er1+r1)\n\n    # ca-layer\n\n    # part 1\n    ca = AveragePooling2D(pool_size = (32,32), padding='valid', strides = 32//1)(er1) # Stride = (input_size//output_size)  Kernel size = input_size - (output_size-1)*stride  \n\n    # basic block\n    ca = Conv2D(4, 1, padding='valid')(ca)\n    ca = ReLU()(ca)\n\n    #basic block sig\n    ca = Conv2D(64, 1, padding='valid', activation = 'sigmoid')(ca)\n    z = Multiply()([er1, ca])\n    \n    return z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, _), (x_test, _) = cifar10.load_data()\n\n# Scaling the images beteen 0 and 1\nx_train = x_train/255.0\nx_test = x_test/255.0\n\n# Real images are labels\ny_train = x_train\ny_test = x_test\n\n# Adding noise to the images\nnoise = \"gaussian\"\nmean = 0\nvar = 0.01\n\nx_train = add_noise(y_train, mean, var, noise)\nx_test = add_noise(y_test, mean, var, noise)\n\n\nX = Input((32,32,3))\n\n# feature extraction\nx = Conv2D(64, 3, padding='same')(X)\nx = ReLU()(x)\n\n# EAM-1\nblock1 = eam_block(x)\n\n# EAM-2\nblock2 = eam_block(block1)\n\n# EAM-3\nblock3 = eam_block(block2)\n\n# EAM-4\nblock4 = eam_block(block3)\n\n# tail \ntail = Conv2D(3, 3, padding='same')(block4)\nout = tail + X\n\nmodel = Model(inputs = X, outputs = out)\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), loss = 'mae')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nbatch_size = 64\n#model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), loss = 'mae')\nhistory = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_denoised(x_test, y_test, model, num_images=12)\nprint(get_metric(model, x_test, y_test))\ndraw_plot(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}